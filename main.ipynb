{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "data_trans = transforms.Compose([\n",
    "                                transforms.Resize((224,224)),\n",
    "                                  transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "dataset = datasets.ImageFolder(root = \"PokemonData\", transform = data_trans)\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "dev_size = int(len(dataset) - train_size)\n",
    "\n",
    "train_set, dev_set = random_split(dataset, [train_size, dev_size])\n",
    "\n",
    "batchSize = 32\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = batchSize, shuffle = True)\n",
    "dev_loader = DataLoader(dev_set, batch_size = batchSize, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alihu\\Documents\\Projects\\PokeDex\\pokeenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alihu\\Documents\\Projects\\PokeDex\\pokeenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet101(pretrained = True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 150)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 10e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss: 0.05840962380170822\n",
      "Epoch : 0 Loss: 0.17848260700702667\n",
      "Epoch : 0 Loss: 0.183319553732872\n",
      "Epoch : 0 Loss: 0.08374486118555069\n",
      "Epoch : 0 Loss: 0.07170655578374863\n",
      "Epoch : 0 Loss: 0.061117734760046005\n",
      "Epoch : 0 Loss: 0.06908971071243286\n",
      "Epoch : 0 Loss: 0.06790728867053986\n",
      "Epoch : 0 Loss: 0.0941804051399231\n",
      "Epoch : 0 Loss: 0.06356559693813324\n",
      "Epoch : 0 Loss: 0.07608997821807861\n",
      "Epoch : 0 Loss: 0.07806649804115295\n",
      "Epoch : 0 Loss: 0.07186968624591827\n",
      "Epoch : 0 Loss: 0.07123015075922012\n",
      "Epoch : 0 Loss: 0.06121000647544861\n",
      "Epoch : 0 Loss: 0.06608516722917557\n",
      "Epoch : 0 Loss: 0.060740504413843155\n",
      "Epoch : 0 Loss: 0.05834100395441055\n",
      "Epoch : 0 Loss: 0.06006963551044464\n",
      "Epoch : 0 Loss: 0.0612688846886158\n",
      "Epoch : 0 Loss: 0.059783171862363815\n",
      "Epoch : 0 Loss: 0.058146532624959946\n",
      "Epoch : 0 Loss: 0.05904241278767586\n",
      "Epoch : 0 Loss: 0.0580902062356472\n",
      "Epoch : 0 Loss: 0.05863013118505478\n",
      "Epoch : 0 Loss: 0.05937424674630165\n",
      "Epoch : 0 Loss: 0.05879533290863037\n",
      "Epoch : 0 Loss: 0.05828123539686203\n",
      "Epoch : 0 Loss: 0.058664288371801376\n",
      "Epoch : 0 Loss: 0.05878283828496933\n",
      "Epoch : 0 Loss: 0.05863884091377258\n",
      "Epoch : 0 Loss: 0.05864108353853226\n",
      "Epoch : 0 Loss: 0.059453144669532776\n",
      "Epoch : 0 Loss: 0.05902804061770439\n",
      "Epoch : 0 Loss: 0.05892829969525337\n",
      "Epoch : 0 Loss: 0.058777809143066406\n",
      "Epoch : 0 Loss: 0.05865372717380524\n",
      "Epoch : 0 Loss: 0.05857716500759125\n",
      "Epoch : 0 Loss: 0.058401454240083694\n",
      "Epoch : 0 Loss: 0.058956798166036606\n",
      "Epoch : 0 Loss: 0.058468885719776154\n",
      "Epoch : 0 Loss: 0.05870351940393448\n",
      "Epoch : 0 Loss: 0.058733414858579636\n",
      "Epoch : 0 Loss: 0.058806709945201874\n",
      "Epoch : 0 Loss: 0.05833132192492485\n",
      "Epoch : 0 Loss: 0.058601442724466324\n",
      "Epoch : 0 Loss: 0.058184411376714706\n",
      "Epoch : 0 Loss: 0.05838211253285408\n",
      "Epoch : 0 Loss: 0.058618031442165375\n",
      "Epoch : 0 Loss: 0.058854054659605026\n",
      "Epoch : 0 Loss: 0.058763545006513596\n",
      "Epoch : 0 Loss: 0.05844746530056\n",
      "Epoch : 0 Loss: 0.05859508365392685\n",
      "Epoch : 0 Loss: 0.05861774459481239\n",
      "Epoch : 0 Loss: 0.05859578773379326\n",
      "Epoch : 0 Loss: 0.05875096097588539\n",
      "Epoch : 0 Loss: 0.05833345279097557\n",
      "Epoch : 0 Loss: 0.058847732841968536\n",
      "Epoch : 0 Loss: 0.05849425494670868\n",
      "Epoch : 0 Loss: 0.057911477982997894\n",
      "Epoch : 0 Loss: 0.05921550095081329\n",
      "Epoch : 0 Loss: 0.05880410969257355\n",
      "Epoch : 0 Loss: 0.05863345414400101\n",
      "Epoch : 0 Loss: 0.059172842651605606\n",
      "Epoch : 0 Loss: 0.05850639566779137\n",
      "Epoch : 0 Loss: 0.05892672389745712\n",
      "Epoch : 0 Loss: 0.05819877237081528\n",
      "Epoch : 0 Loss: 0.057951491326093674\n",
      "Epoch : 0 Loss: 0.058595769107341766\n",
      "Epoch : 0 Loss: 0.05891517922282219\n",
      "Epoch : 0 Loss: 0.05917507782578468\n",
      "Epoch : 0 Loss: 0.05925273522734642\n",
      "Epoch : 0 Loss: 0.058262329548597336\n",
      "Epoch : 0 Loss: 0.05893593654036522\n",
      "Epoch : 0 Loss: 0.05862456187605858\n",
      "Epoch : 0 Loss: 0.058057092130184174\n",
      "Epoch : 0 Loss: 0.059142280369997025\n",
      "Epoch : 0 Loss: 0.05822419375181198\n",
      "Epoch : 0 Loss: 0.05865882709622383\n",
      "Epoch : 0 Loss: 0.05868173763155937\n",
      "Epoch : 0 Loss: 0.059179067611694336\n",
      "Epoch : 0 Loss: 0.05867227539420128\n",
      "Epoch : 0 Loss: 0.058724675327539444\n",
      "Epoch : 0 Loss: 0.05858059599995613\n",
      "Epoch : 0 Loss: 0.059010978788137436\n",
      "Epoch : 0 Loss: 0.05866385996341705\n",
      "Epoch : 0 Loss: 0.058714281767606735\n",
      "Epoch : 0 Loss: 0.05834423378109932\n",
      "Epoch : 0 Loss: 0.05876776576042175\n",
      "Epoch : 0 Loss: 0.05863422155380249\n",
      "Epoch : 0 Loss: 0.05848677083849907\n",
      "Epoch : 0 Loss: 0.058862291276454926\n",
      "Epoch : 0 Loss: 0.05820118263363838\n",
      "Epoch : 0 Loss: 0.05834779888391495\n",
      "Epoch : 0 Loss: 0.0581904873251915\n",
      "Epoch : 0 Loss: 0.0591735914349556\n",
      "Epoch : 0 Loss: 0.05809576064348221\n",
      "Epoch : 0 Loss: 0.05850803852081299\n",
      "Epoch : 0 Loss: 0.05919155478477478\n",
      "Epoch : 0 Loss: 0.05860070511698723\n",
      "Epoch : 0 Loss: 0.05892454832792282\n",
      "Epoch : 0 Loss: 0.0583975613117218\n",
      "Epoch : 0 Loss: 0.05882246419787407\n",
      "Epoch : 0 Loss: 0.05898693576455116\n",
      "Epoch : 0 Loss: 0.05842747166752815\n",
      "Epoch : 0 Loss: 0.058311909437179565\n",
      "Epoch : 0 Loss: 0.058492425829172134\n",
      "Epoch : 0 Loss: 0.05827246233820915\n",
      "Epoch : 0 Loss: 0.05816812813282013\n",
      "Epoch : 0 Loss: 0.05807455629110336\n",
      "Epoch : 0 Loss: 0.05842036008834839\n",
      "Epoch : 0 Loss: 0.0584297738969326\n",
      "Epoch : 0 Loss: 0.058925628662109375\n",
      "Epoch : 0 Loss: 0.05819065123796463\n",
      "Epoch : 0 Loss: 0.05754243955016136\n",
      "Epoch : 0 Loss: 0.058147720992565155\n",
      "Epoch : 0 Loss: 0.058383759111166\n",
      "Epoch : 0 Loss: 0.05788780376315117\n",
      "Epoch : 0 Loss: 0.057280831038951874\n",
      "Epoch : 0 Loss: 0.058198947459459305\n",
      "Epoch : 0 Loss: 0.058731403201818466\n",
      "Epoch : 0 Loss: 0.057453736662864685\n",
      "Epoch : 0 Loss: 0.05770927667617798\n",
      "Epoch : 0 Loss: 0.05744064599275589\n",
      "Epoch : 0 Loss: 0.05750691890716553\n",
      "Epoch : 0 Loss: 0.05698994919657707\n",
      "Epoch : 0 Loss: 0.05773171782493591\n",
      "Epoch : 0 Loss: 0.05712183937430382\n",
      "Epoch : 0 Loss: 0.05799691751599312\n",
      "Epoch : 0 Loss: 0.05704231187701225\n",
      "Epoch : 0 Loss: 0.05710425227880478\n",
      "Epoch : 0 Loss: 0.05990580469369888\n",
      "Epoch : 0 Loss: 0.058658186346292496\n",
      "Epoch : 0 Loss: 0.05794547498226166\n",
      "Epoch : 0 Loss: 0.05755472555756569\n",
      "Epoch : 0 Loss: 0.058539219200611115\n",
      "Epoch : 0 Loss: 0.05779632180929184\n",
      "Epoch : 0 Loss: 0.057852573692798615\n",
      "Epoch : 0 Loss: 0.05599142983555794\n",
      "Epoch : 0 Loss: 0.05663919076323509\n",
      "Epoch : 0 Loss: 0.056947968900203705\n",
      "Epoch : 0 Loss: 0.056127894669771194\n",
      "Epoch : 0 Loss: 0.05828167498111725\n",
      "Epoch : 0 Loss: 0.05669446662068367\n",
      "Epoch : 0 Loss: 0.05785441771149635\n",
      "Epoch : 0 Loss: 0.05717608705163002\n",
      "Epoch : 0 Loss: 0.056106578558683395\n",
      "Epoch : 0 Loss: 0.057631559669971466\n",
      "Epoch : 0 Loss: 0.0577220693230629\n",
      "Epoch : 0 Loss: 0.058507803827524185\n",
      "Epoch : 0 Loss: 0.05875111743807793\n",
      "Epoch : 0 Loss: 0.05763716995716095\n",
      "Epoch : 0 Loss: 0.055621374398469925\n",
      "Epoch : 0 Loss: 0.056821584701538086\n",
      "Epoch : 0 Loss: 0.056637782603502274\n",
      "Epoch : 0 Loss: 0.05764966458082199\n",
      "Epoch : 0 Loss: 0.05566152557730675\n",
      "Epoch : 0 Loss: 0.05586865171790123\n",
      "Epoch : 0 Loss: 0.05774599686264992\n",
      "Epoch : 0 Loss: 0.057417407631874084\n",
      "Epoch : 0 Loss: 0.0568615198135376\n",
      "Epoch : 0 Loss: 0.0561685785651207\n",
      "Epoch : 0 Loss: 0.05623854324221611\n",
      "Epoch : 0 Loss: 0.05617312341928482\n",
      "Epoch : 0 Loss: 0.056334301829338074\n",
      "Epoch : 0 Loss: 0.056464146822690964\n",
      "Epoch : 0 Loss: 0.058629751205444336\n",
      "Epoch : 0 Loss: 0.057020895183086395\n",
      "Epoch : 0 Loss: 0.05723527818918228\n",
      "Epoch : 0 Loss: 0.05722223222255707\n",
      "Epoch : 0 Loss: 0.05662873014807701\n",
      "Epoch : 1 Loss: 0.057907067239284515\n",
      "Epoch : 1 Loss: 0.057439133524894714\n",
      "Epoch : 1 Loss: 0.05613004043698311\n",
      "Epoch : 1 Loss: 0.0562467984855175\n",
      "Epoch : 1 Loss: 0.05874903127551079\n",
      "Epoch : 1 Loss: 0.05612935498356819\n",
      "Epoch : 1 Loss: 0.057820603251457214\n",
      "Epoch : 1 Loss: 0.05695290118455887\n",
      "Epoch : 1 Loss: 0.0567508339881897\n",
      "Epoch : 1 Loss: 0.05689860135316849\n",
      "Epoch : 1 Loss: 0.055033836513757706\n",
      "Epoch : 1 Loss: 0.05590669810771942\n",
      "Epoch : 1 Loss: 0.05724035203456879\n",
      "Epoch : 1 Loss: 0.05858316645026207\n",
      "Epoch : 1 Loss: 0.056968752294778824\n",
      "Epoch : 1 Loss: 0.056785400956869125\n",
      "Epoch : 1 Loss: 0.05814720317721367\n",
      "Epoch : 1 Loss: 0.05717525631189346\n",
      "Epoch : 1 Loss: 0.05670570209622383\n",
      "Epoch : 1 Loss: 0.05766548588871956\n",
      "Epoch : 1 Loss: 0.05624260753393173\n",
      "Epoch : 1 Loss: 0.05664815008640289\n",
      "Epoch : 1 Loss: 0.05677197128534317\n",
      "Epoch : 1 Loss: 0.056372564285993576\n",
      "Epoch : 1 Loss: 0.055206600576639175\n",
      "Epoch : 1 Loss: 0.055968545377254486\n",
      "Epoch : 1 Loss: 0.057474032044410706\n",
      "Epoch : 1 Loss: 0.056908540427684784\n",
      "Epoch : 1 Loss: 0.056553054600954056\n",
      "Epoch : 1 Loss: 0.05509122833609581\n",
      "Epoch : 1 Loss: 0.05565112829208374\n",
      "Epoch : 1 Loss: 0.058578141033649445\n",
      "Epoch : 1 Loss: 0.057109761983156204\n",
      "Epoch : 1 Loss: 0.056359775364398956\n",
      "Epoch : 1 Loss: 0.05861113965511322\n",
      "Epoch : 1 Loss: 0.055698372423648834\n",
      "Epoch : 1 Loss: 0.05722712352871895\n",
      "Epoch : 1 Loss: 0.05673326551914215\n",
      "Epoch : 1 Loss: 0.056838259100914\n",
      "Epoch : 1 Loss: 0.05674033239483833\n",
      "Epoch : 1 Loss: 0.054024238139390945\n",
      "Epoch : 1 Loss: 0.05632057413458824\n",
      "Epoch : 1 Loss: 0.057922858744859695\n",
      "Epoch : 1 Loss: 0.05749373883008957\n",
      "Epoch : 1 Loss: 0.055199600756168365\n",
      "Epoch : 1 Loss: 0.057162147015333176\n",
      "Epoch : 1 Loss: 0.05585860088467598\n",
      "Epoch : 1 Loss: 0.057093504816293716\n",
      "Epoch : 1 Loss: 0.05551492050290108\n",
      "Epoch : 1 Loss: 0.055404145270586014\n",
      "Epoch : 1 Loss: 0.05519858002662659\n",
      "Epoch : 1 Loss: 0.05848928168416023\n",
      "Epoch : 1 Loss: 0.05446799471974373\n",
      "Epoch : 1 Loss: 0.055933333933353424\n",
      "Epoch : 1 Loss: 0.055635903030633926\n",
      "Epoch : 1 Loss: 0.05499442294239998\n",
      "Epoch : 1 Loss: 0.05588686466217041\n",
      "Epoch : 1 Loss: 0.0559062696993351\n",
      "Epoch : 1 Loss: 0.05373452231287956\n",
      "Epoch : 1 Loss: 0.0576210543513298\n",
      "Epoch : 1 Loss: 0.05594601482152939\n",
      "Epoch : 1 Loss: 0.055328983813524246\n",
      "Epoch : 1 Loss: 0.05806449055671692\n",
      "Epoch : 1 Loss: 0.05530399829149246\n",
      "Epoch : 1 Loss: 0.05389058589935303\n",
      "Epoch : 1 Loss: 0.05648086965084076\n",
      "Epoch : 1 Loss: 0.05501912906765938\n",
      "Epoch : 1 Loss: 0.05571378394961357\n",
      "Epoch : 1 Loss: 0.054909758269786835\n",
      "Epoch : 1 Loss: 0.0531870536506176\n",
      "Epoch : 1 Loss: 0.054834578186273575\n",
      "Epoch : 1 Loss: 0.05576377362012863\n",
      "Epoch : 1 Loss: 0.054164450615644455\n",
      "Epoch : 1 Loss: 0.05434608459472656\n",
      "Epoch : 1 Loss: 0.05395771190524101\n",
      "Epoch : 1 Loss: 0.055115409195423126\n",
      "Epoch : 1 Loss: 0.054678402841091156\n",
      "Epoch : 1 Loss: 0.05483352020382881\n",
      "Epoch : 1 Loss: 0.051653794944286346\n",
      "Epoch : 1 Loss: 0.054077595472335815\n",
      "Epoch : 1 Loss: 0.05507730692625046\n",
      "Epoch : 1 Loss: 0.05493638291954994\n",
      "Epoch : 1 Loss: 0.05467761680483818\n",
      "Epoch : 1 Loss: 0.0538199357688427\n",
      "Epoch : 1 Loss: 0.056534022092819214\n",
      "Epoch : 1 Loss: 0.05448407679796219\n",
      "Epoch : 1 Loss: 0.05532735586166382\n",
      "Epoch : 1 Loss: 0.0549861416220665\n",
      "Epoch : 1 Loss: 0.056061822921037674\n",
      "Epoch : 1 Loss: 0.05472850427031517\n",
      "Epoch : 1 Loss: 0.05216633155941963\n",
      "Epoch : 1 Loss: 0.05347888171672821\n",
      "Epoch : 1 Loss: 0.05228754132986069\n",
      "Epoch : 1 Loss: 0.053796350955963135\n",
      "Epoch : 1 Loss: 0.05319063737988472\n",
      "Epoch : 1 Loss: 0.05576930195093155\n",
      "Epoch : 1 Loss: 0.05308994650840759\n",
      "Epoch : 1 Loss: 0.05373785272240639\n",
      "Epoch : 1 Loss: 0.05491654947400093\n",
      "Epoch : 1 Loss: 0.0545806884765625\n",
      "Epoch : 1 Loss: 0.053628068417310715\n",
      "Epoch : 1 Loss: 0.05279519408941269\n",
      "Epoch : 1 Loss: 0.055635493248701096\n",
      "Epoch : 1 Loss: 0.05383455380797386\n",
      "Epoch : 1 Loss: 0.05348527804017067\n",
      "Epoch : 1 Loss: 0.05229547992348671\n",
      "Epoch : 1 Loss: 0.05283314362168312\n",
      "Epoch : 1 Loss: 0.054949913173913956\n",
      "Epoch : 1 Loss: 0.055039115250110626\n",
      "Epoch : 1 Loss: 0.05126045644283295\n",
      "Epoch : 1 Loss: 0.053553346544504166\n",
      "Epoch : 1 Loss: 0.056024763733148575\n",
      "Epoch : 1 Loss: 0.054283756762742996\n",
      "Epoch : 1 Loss: 0.05322980508208275\n",
      "Epoch : 1 Loss: 0.051974982023239136\n",
      "Epoch : 1 Loss: 0.05370025709271431\n",
      "Epoch : 1 Loss: 0.05315990000963211\n",
      "Epoch : 1 Loss: 0.05247624218463898\n",
      "Epoch : 1 Loss: 0.05363978445529938\n",
      "Epoch : 1 Loss: 0.05363582447171211\n",
      "Epoch : 1 Loss: 0.0534454807639122\n",
      "Epoch : 1 Loss: 0.05302748084068298\n",
      "Epoch : 1 Loss: 0.05358591675758362\n",
      "Epoch : 1 Loss: 0.05498805269598961\n",
      "Epoch : 1 Loss: 0.05622554197907448\n",
      "Epoch : 1 Loss: 0.05128318816423416\n",
      "Epoch : 1 Loss: 0.05580408126115799\n",
      "Epoch : 1 Loss: 0.053598467260599136\n",
      "Epoch : 1 Loss: 0.052364811301231384\n",
      "Epoch : 1 Loss: 0.05197664350271225\n",
      "Epoch : 1 Loss: 0.052610889077186584\n",
      "Epoch : 1 Loss: 0.054618969559669495\n",
      "Epoch : 1 Loss: 0.05493887886404991\n",
      "Epoch : 1 Loss: 0.054552290588617325\n",
      "Epoch : 1 Loss: 0.05635474994778633\n",
      "Epoch : 1 Loss: 0.05086606740951538\n",
      "Epoch : 1 Loss: 0.05545486882328987\n",
      "Epoch : 1 Loss: 0.05226333439350128\n",
      "Epoch : 1 Loss: 0.0507311075925827\n",
      "Epoch : 1 Loss: 0.05257910490036011\n",
      "Epoch : 1 Loss: 0.05383503437042236\n",
      "Epoch : 1 Loss: 0.0532340332865715\n",
      "Epoch : 1 Loss: 0.05260729789733887\n",
      "Epoch : 1 Loss: 0.052431073039770126\n",
      "Epoch : 1 Loss: 0.05092215910553932\n",
      "Epoch : 1 Loss: 0.05289527773857117\n",
      "Epoch : 1 Loss: 0.05498667061328888\n",
      "Epoch : 1 Loss: 0.05012422055006027\n",
      "Epoch : 1 Loss: 0.05200589820742607\n",
      "Epoch : 1 Loss: 0.05462741479277611\n",
      "Epoch : 1 Loss: 0.05141257122159004\n",
      "Epoch : 1 Loss: 0.05259884148836136\n",
      "Epoch : 1 Loss: 0.054352615028619766\n",
      "Epoch : 1 Loss: 0.053894639015197754\n",
      "Epoch : 1 Loss: 0.05245058611035347\n",
      "Epoch : 1 Loss: 0.05357053503394127\n",
      "Epoch : 1 Loss: 0.053198013454675674\n",
      "Epoch : 1 Loss: 0.0504930280148983\n",
      "Epoch : 1 Loss: 0.053103331476449966\n",
      "Epoch : 1 Loss: 0.054690711200237274\n",
      "Epoch : 1 Loss: 0.051934801042079926\n",
      "Epoch : 1 Loss: 0.05276435613632202\n",
      "Epoch : 1 Loss: 0.05641366168856621\n",
      "Epoch : 1 Loss: 0.050813257694244385\n",
      "Epoch : 1 Loss: 0.05139164254069328\n",
      "Epoch : 1 Loss: 0.05351782590150833\n",
      "Epoch : 1 Loss: 0.052081502974033356\n",
      "Epoch : 1 Loss: 0.055472515523433685\n",
      "Epoch : 1 Loss: 0.056032076478004456\n",
      "Epoch : 1 Loss: 0.0518631637096405\n",
      "Epoch : 1 Loss: 0.0518520250916481\n",
      "Epoch : 2 Loss: 0.0539836660027504\n",
      "Epoch : 2 Loss: 0.05054951459169388\n",
      "Epoch : 2 Loss: 0.05222173407673836\n",
      "Epoch : 2 Loss: 0.051919665187597275\n",
      "Epoch : 2 Loss: 0.05042809620499611\n",
      "Epoch : 2 Loss: 0.05249305069446564\n",
      "Epoch : 2 Loss: 0.05600997805595398\n",
      "Epoch : 2 Loss: 0.05096573755145073\n",
      "Epoch : 2 Loss: 0.05412590503692627\n",
      "Epoch : 2 Loss: 0.055237386375665665\n",
      "Epoch : 2 Loss: 0.05072610080242157\n",
      "Epoch : 2 Loss: 0.048283688724040985\n",
      "Epoch : 2 Loss: 0.0513426847755909\n",
      "Epoch : 2 Loss: 0.049549032002687454\n",
      "Epoch : 2 Loss: 0.05152563378214836\n",
      "Epoch : 2 Loss: 0.050048016011714935\n",
      "Epoch : 2 Loss: 0.052553582936525345\n",
      "Epoch : 2 Loss: 0.053780555725097656\n",
      "Epoch : 2 Loss: 0.050709206610918045\n",
      "Epoch : 2 Loss: 0.050873108208179474\n",
      "Epoch : 2 Loss: 0.05200015753507614\n",
      "Epoch : 2 Loss: 0.05002785846590996\n",
      "Epoch : 2 Loss: 0.05352475494146347\n",
      "Epoch : 2 Loss: 0.05039703845977783\n",
      "Epoch : 2 Loss: 0.05282702296972275\n",
      "Epoch : 2 Loss: 0.05527064576745033\n",
      "Epoch : 2 Loss: 0.04955804720520973\n",
      "Epoch : 2 Loss: 0.04974933713674545\n",
      "Epoch : 2 Loss: 0.05258749797940254\n",
      "Epoch : 2 Loss: 0.05226906016469002\n",
      "Epoch : 2 Loss: 0.049586523324251175\n",
      "Epoch : 2 Loss: 0.05354027450084686\n",
      "Epoch : 2 Loss: 0.05160800367593765\n",
      "Epoch : 2 Loss: 0.0546688511967659\n",
      "Epoch : 2 Loss: 0.0525827631354332\n",
      "Epoch : 2 Loss: 0.053554464131593704\n",
      "Epoch : 2 Loss: 0.05063624680042267\n",
      "Epoch : 2 Loss: 0.0532778762280941\n",
      "Epoch : 2 Loss: 0.0545228086411953\n",
      "Epoch : 2 Loss: 0.05317322164773941\n",
      "Epoch : 2 Loss: 0.05148148164153099\n",
      "Epoch : 2 Loss: 0.051663726568222046\n",
      "Epoch : 2 Loss: 0.05120053142309189\n",
      "Epoch : 2 Loss: 0.05185595899820328\n",
      "Epoch : 2 Loss: 0.05299191176891327\n",
      "Epoch : 2 Loss: 0.053449179977178574\n",
      "Epoch : 2 Loss: 0.052524957805871964\n",
      "Epoch : 2 Loss: 0.05168060585856438\n",
      "Epoch : 2 Loss: 0.05117974802851677\n",
      "Epoch : 2 Loss: 0.05742132291197777\n",
      "Epoch : 2 Loss: 0.05428856238722801\n",
      "Epoch : 2 Loss: 0.05038820207118988\n",
      "Epoch : 2 Loss: 0.054422006011009216\n",
      "Epoch : 2 Loss: 0.05272085219621658\n",
      "Epoch : 2 Loss: 0.050771601498126984\n",
      "Epoch : 2 Loss: 0.050987016409635544\n",
      "Epoch : 2 Loss: 0.05157189071178436\n",
      "Epoch : 2 Loss: 0.05053717643022537\n",
      "Epoch : 2 Loss: 0.055654797703027725\n",
      "Epoch : 2 Loss: 0.0504816509783268\n",
      "Epoch : 2 Loss: 0.05214788392186165\n",
      "Epoch : 2 Loss: 0.05176141485571861\n",
      "Epoch : 2 Loss: 0.05036964640021324\n",
      "Epoch : 2 Loss: 0.05243182182312012\n",
      "Epoch : 2 Loss: 0.05217990651726723\n",
      "Epoch : 2 Loss: 0.050124429166316986\n",
      "Epoch : 2 Loss: 0.05066428333520889\n",
      "Epoch : 2 Loss: 0.0522879883646965\n",
      "Epoch : 2 Loss: 0.05200175940990448\n",
      "Epoch : 2 Loss: 0.05220939591526985\n",
      "Epoch : 2 Loss: 0.04956750571727753\n",
      "Epoch : 2 Loss: 0.052003782242536545\n",
      "Epoch : 2 Loss: 0.05067561939358711\n",
      "Epoch : 2 Loss: 0.050175003707408905\n",
      "Epoch : 2 Loss: 0.0501425601541996\n",
      "Epoch : 2 Loss: 0.048897385597229004\n",
      "Epoch : 2 Loss: 0.04891529306769371\n",
      "Epoch : 2 Loss: 0.048373375087976456\n",
      "Epoch : 2 Loss: 0.051665082573890686\n",
      "Epoch : 2 Loss: 0.05107538774609566\n",
      "Epoch : 2 Loss: 0.05074121803045273\n",
      "Epoch : 2 Loss: 0.05276774242520332\n",
      "Epoch : 2 Loss: 0.052194055169820786\n",
      "Epoch : 2 Loss: 0.05249841511249542\n",
      "Epoch : 2 Loss: 0.05175090208649635\n",
      "Epoch : 2 Loss: 0.051325056701898575\n",
      "Epoch : 2 Loss: 0.04958806931972504\n",
      "Epoch : 2 Loss: 0.05285191535949707\n",
      "Epoch : 2 Loss: 0.05476024001836777\n",
      "Epoch : 2 Loss: 0.05293530970811844\n",
      "Epoch : 2 Loss: 0.051654648035764694\n",
      "Epoch : 2 Loss: 0.04992441460490227\n",
      "Epoch : 2 Loss: 0.05211572349071503\n",
      "Epoch : 2 Loss: 0.05002148449420929\n",
      "Epoch : 2 Loss: 0.054998092353343964\n",
      "Epoch : 2 Loss: 0.051597703248262405\n",
      "Epoch : 2 Loss: 0.05090787634253502\n",
      "Epoch : 2 Loss: 0.05122043564915657\n",
      "Epoch : 2 Loss: 0.049252286553382874\n",
      "Epoch : 2 Loss: 0.050897710025310516\n",
      "Epoch : 2 Loss: 0.04971902072429657\n",
      "Epoch : 2 Loss: 0.0490567609667778\n",
      "Epoch : 2 Loss: 0.05510133504867554\n",
      "Epoch : 2 Loss: 0.05336426943540573\n",
      "Epoch : 2 Loss: 0.05233262851834297\n",
      "Epoch : 2 Loss: 0.05335819721221924\n",
      "Epoch : 2 Loss: 0.04912887141108513\n",
      "Epoch : 2 Loss: 0.04981327801942825\n",
      "Epoch : 2 Loss: 0.05045966058969498\n",
      "Epoch : 2 Loss: 0.04888338968157768\n",
      "Epoch : 2 Loss: 0.05029357224702835\n",
      "Epoch : 2 Loss: 0.053433675318956375\n",
      "Epoch : 2 Loss: 0.04921596869826317\n",
      "Epoch : 2 Loss: 0.049869000911712646\n",
      "Epoch : 2 Loss: 0.04917685315012932\n",
      "Epoch : 2 Loss: 0.0497128963470459\n",
      "Epoch : 2 Loss: 0.04913118854165077\n",
      "Epoch : 2 Loss: 0.051002319902181625\n",
      "Epoch : 2 Loss: 0.05119868740439415\n",
      "Epoch : 2 Loss: 0.04871048405766487\n",
      "Epoch : 2 Loss: 0.04837452247738838\n",
      "Epoch : 2 Loss: 0.05368257313966751\n",
      "Epoch : 2 Loss: 0.04906712844967842\n",
      "Epoch : 2 Loss: 0.05046136677265167\n",
      "Epoch : 2 Loss: 0.04853544384241104\n",
      "Epoch : 2 Loss: 0.05027078837156296\n",
      "Epoch : 2 Loss: 0.04980447515845299\n",
      "Epoch : 2 Loss: 0.050788428634405136\n",
      "Epoch : 2 Loss: 0.049156174063682556\n",
      "Epoch : 2 Loss: 0.0464954636991024\n",
      "Epoch : 2 Loss: 0.04835173487663269\n",
      "Epoch : 2 Loss: 0.05272132530808449\n",
      "Epoch : 2 Loss: 0.05043642595410347\n",
      "Epoch : 2 Loss: 0.05047180876135826\n",
      "Epoch : 2 Loss: 0.05065970495343208\n",
      "Epoch : 2 Loss: 0.05583421140909195\n",
      "Epoch : 2 Loss: 0.05086931213736534\n",
      "Epoch : 2 Loss: 0.05206434428691864\n",
      "Epoch : 2 Loss: 0.04986758530139923\n",
      "Epoch : 2 Loss: 0.05059779807925224\n",
      "Epoch : 2 Loss: 0.049174826592206955\n",
      "Epoch : 2 Loss: 0.0520603246986866\n",
      "Epoch : 2 Loss: 0.05001178756356239\n",
      "Epoch : 2 Loss: 0.0524962954223156\n",
      "Epoch : 2 Loss: 0.04867524653673172\n",
      "Epoch : 2 Loss: 0.049762096256017685\n",
      "Epoch : 2 Loss: 0.053026240319013596\n",
      "Epoch : 2 Loss: 0.05059262365102768\n",
      "Epoch : 2 Loss: 0.04714024066925049\n",
      "Epoch : 2 Loss: 0.05063774809241295\n",
      "Epoch : 2 Loss: 0.05158371850848198\n",
      "Epoch : 2 Loss: 0.04981663450598717\n",
      "Epoch : 2 Loss: 0.05167784541845322\n",
      "Epoch : 2 Loss: 0.05056462809443474\n",
      "Epoch : 2 Loss: 0.049649644643068314\n",
      "Epoch : 2 Loss: 0.05220421776175499\n",
      "Epoch : 2 Loss: 0.05027724802494049\n",
      "Epoch : 2 Loss: 0.05188777297735214\n",
      "Epoch : 2 Loss: 0.04847341403365135\n",
      "Epoch : 2 Loss: 0.05057889223098755\n",
      "Epoch : 2 Loss: 0.05047891288995743\n",
      "Epoch : 2 Loss: 0.048346661031246185\n",
      "Epoch : 2 Loss: 0.04705212265253067\n",
      "Epoch : 2 Loss: 0.0491512268781662\n",
      "Epoch : 2 Loss: 0.04944390431046486\n",
      "Epoch : 2 Loss: 0.0498603917658329\n",
      "Epoch : 2 Loss: 0.04957462474703789\n",
      "Epoch : 2 Loss: 0.047234367579221725\n",
      "Epoch : 2 Loss: 0.050354987382888794\n",
      "Epoch : 2 Loss: 0.05313987284898758\n",
      "Epoch : 2 Loss: 0.046472277492284775\n",
      "Epoch : 3 Loss: 0.04942163825035095\n",
      "Epoch : 3 Loss: 0.047790076583623886\n",
      "Epoch : 3 Loss: 0.05027495697140694\n",
      "Epoch : 3 Loss: 0.047210849821567535\n",
      "Epoch : 3 Loss: 0.0477810800075531\n",
      "Epoch : 3 Loss: 0.049203187227249146\n",
      "Epoch : 3 Loss: 0.04742896184325218\n",
      "Epoch : 3 Loss: 0.05238393694162369\n",
      "Epoch : 3 Loss: 0.04715019464492798\n",
      "Epoch : 3 Loss: 0.04979522526264191\n",
      "Epoch : 3 Loss: 0.053298309445381165\n",
      "Epoch : 3 Loss: 0.04501871392130852\n",
      "Epoch : 3 Loss: 0.04736218973994255\n",
      "Epoch : 3 Loss: 0.04930834844708443\n",
      "Epoch : 3 Loss: 0.05079857259988785\n",
      "Epoch : 3 Loss: 0.04661014303565025\n",
      "Epoch : 3 Loss: 0.04597575590014458\n",
      "Epoch : 3 Loss: 0.04937891289591789\n",
      "Epoch : 3 Loss: 0.047377809882164\n",
      "Epoch : 3 Loss: 0.048363715410232544\n",
      "Epoch : 3 Loss: 0.050179582089185715\n",
      "Epoch : 3 Loss: 0.04627702757716179\n",
      "Epoch : 3 Loss: 0.04895664379000664\n",
      "Epoch : 3 Loss: 0.048880238085985184\n",
      "Epoch : 3 Loss: 0.04958547651767731\n",
      "Epoch : 3 Loss: 0.04468918591737747\n",
      "Epoch : 3 Loss: 0.05097924545407295\n",
      "Epoch : 3 Loss: 0.049055736511945724\n",
      "Epoch : 3 Loss: 0.04902368411421776\n",
      "Epoch : 3 Loss: 0.04906604811549187\n",
      "Epoch : 3 Loss: 0.047719404101371765\n",
      "Epoch : 3 Loss: 0.04590526595711708\n",
      "Epoch : 3 Loss: 0.050627969205379486\n",
      "Epoch : 3 Loss: 0.049835070967674255\n",
      "Epoch : 3 Loss: 0.04749082773923874\n",
      "Epoch : 3 Loss: 0.05038909986615181\n",
      "Epoch : 3 Loss: 0.04712691530585289\n",
      "Epoch : 3 Loss: 0.048125579953193665\n",
      "Epoch : 3 Loss: 0.051601529121398926\n",
      "Epoch : 3 Loss: 0.04595892131328583\n",
      "Epoch : 3 Loss: 0.05100764334201813\n",
      "Epoch : 3 Loss: 0.04511253535747528\n",
      "Epoch : 3 Loss: 0.0470738559961319\n",
      "Epoch : 3 Loss: 0.047050170600414276\n",
      "Epoch : 3 Loss: 0.047966551035642624\n",
      "Epoch : 3 Loss: 0.05260643735527992\n",
      "Epoch : 3 Loss: 0.04676888883113861\n",
      "Epoch : 3 Loss: 0.04722537100315094\n",
      "Epoch : 3 Loss: 0.050169773399829865\n",
      "Epoch : 3 Loss: 0.04913472756743431\n",
      "Epoch : 3 Loss: 0.048777732998132706\n",
      "Epoch : 3 Loss: 0.049474213272333145\n",
      "Epoch : 3 Loss: 0.04631383344531059\n",
      "Epoch : 3 Loss: 0.04702233895659447\n",
      "Epoch : 3 Loss: 0.048401616513729095\n",
      "Epoch : 3 Loss: 0.05654717609286308\n",
      "Epoch : 3 Loss: 0.045316025614738464\n",
      "Epoch : 3 Loss: 0.04675205051898956\n",
      "Epoch : 3 Loss: 0.04686535894870758\n",
      "Epoch : 3 Loss: 0.04439375922083855\n",
      "Epoch : 3 Loss: 0.048021115362644196\n",
      "Epoch : 3 Loss: 0.044282376766204834\n",
      "Epoch : 3 Loss: 0.048216111958026886\n",
      "Epoch : 3 Loss: 0.048727165907621384\n",
      "Epoch : 3 Loss: 0.04429231211543083\n",
      "Epoch : 3 Loss: 0.04745781421661377\n",
      "Epoch : 3 Loss: 0.046867888420820236\n",
      "Epoch : 3 Loss: 0.046377554535865784\n",
      "Epoch : 3 Loss: 0.04821481928229332\n",
      "Epoch : 3 Loss: 0.0494215227663517\n",
      "Epoch : 3 Loss: 0.046912986785173416\n",
      "Epoch : 3 Loss: 0.048170123249292374\n",
      "Epoch : 3 Loss: 0.04851088672876358\n",
      "Epoch : 3 Loss: 0.048660505563020706\n",
      "Epoch : 3 Loss: 0.05011164769530296\n",
      "Epoch : 3 Loss: 0.045253004878759384\n",
      "Epoch : 3 Loss: 0.047526054084300995\n",
      "Epoch : 3 Loss: 0.04671293869614601\n",
      "Epoch : 3 Loss: 0.052149783819913864\n",
      "Epoch : 3 Loss: 0.04911746084690094\n",
      "Epoch : 3 Loss: 0.04807887226343155\n",
      "Epoch : 3 Loss: 0.046841543167829514\n",
      "Epoch : 3 Loss: 0.04947062209248543\n",
      "Epoch : 3 Loss: 0.04711303487420082\n",
      "Epoch : 3 Loss: 0.04646636173129082\n",
      "Epoch : 3 Loss: 0.04690593481063843\n",
      "Epoch : 3 Loss: 0.04796460270881653\n",
      "Epoch : 3 Loss: 0.055177006870508194\n",
      "Epoch : 3 Loss: 0.05231541767716408\n",
      "Epoch : 3 Loss: 0.04771929606795311\n",
      "Epoch : 3 Loss: 0.051328692585229874\n",
      "Epoch : 3 Loss: 0.050215113908052444\n",
      "Epoch : 3 Loss: 0.04575099050998688\n",
      "Epoch : 3 Loss: 0.04859863594174385\n",
      "Epoch : 3 Loss: 0.046115145087242126\n",
      "Epoch : 3 Loss: 0.045651841908693314\n",
      "Epoch : 3 Loss: 0.04623079672455788\n",
      "Epoch : 3 Loss: 0.04456816986203194\n",
      "Epoch : 3 Loss: 0.044482313096523285\n",
      "Epoch : 3 Loss: 0.04888009652495384\n",
      "Epoch : 3 Loss: 0.051094185560941696\n",
      "Epoch : 3 Loss: 0.05085271596908569\n",
      "Epoch : 3 Loss: 0.04992956295609474\n",
      "Epoch : 3 Loss: 0.04895332455635071\n",
      "Epoch : 3 Loss: 0.047079816460609436\n",
      "Epoch : 3 Loss: 0.04787049815058708\n",
      "Epoch : 3 Loss: 0.04581088572740555\n",
      "Epoch : 3 Loss: 0.046200092881917953\n",
      "Epoch : 3 Loss: 0.0482986643910408\n",
      "Epoch : 3 Loss: 0.049350835382938385\n",
      "Epoch : 3 Loss: 0.04885648936033249\n",
      "Epoch : 3 Loss: 0.04483140632510185\n",
      "Epoch : 3 Loss: 0.05156135559082031\n",
      "Epoch : 3 Loss: 0.0537993498146534\n",
      "Epoch : 3 Loss: 0.05369751900434494\n",
      "Epoch : 3 Loss: 0.04597393050789833\n",
      "Epoch : 3 Loss: 0.048312317579984665\n",
      "Epoch : 3 Loss: 0.0494953915476799\n",
      "Epoch : 3 Loss: 0.05041104182600975\n",
      "Epoch : 3 Loss: 0.050078269094228745\n",
      "Epoch : 3 Loss: 0.04730452597141266\n",
      "Epoch : 3 Loss: 0.04520978033542633\n",
      "Epoch : 3 Loss: 0.04582489654421806\n",
      "Epoch : 3 Loss: 0.047231584787368774\n",
      "Epoch : 3 Loss: 0.04720853641629219\n",
      "Epoch : 3 Loss: 0.05003097653388977\n",
      "Epoch : 3 Loss: 0.05064305663108826\n",
      "Epoch : 3 Loss: 0.046623971313238144\n",
      "Epoch : 3 Loss: 0.04612572863698006\n",
      "Epoch : 3 Loss: 0.04759874567389488\n",
      "Epoch : 3 Loss: 0.05035347864031792\n",
      "Epoch : 3 Loss: 0.053273364901542664\n",
      "Epoch : 3 Loss: 0.05961979925632477\n",
      "Epoch : 3 Loss: 0.05986836180090904\n",
      "Epoch : 3 Loss: 0.0589614100754261\n",
      "Epoch : 3 Loss: 0.0567883662879467\n",
      "Epoch : 3 Loss: 0.05570651590824127\n",
      "Epoch : 3 Loss: 0.058429449796676636\n",
      "Epoch : 3 Loss: 0.05638387054204941\n",
      "Epoch : 3 Loss: 0.05529520660638809\n",
      "Epoch : 3 Loss: 0.05761100724339485\n",
      "Epoch : 3 Loss: 0.05387042462825775\n",
      "Epoch : 3 Loss: 0.055533844977617264\n",
      "Epoch : 3 Loss: 0.05415736511349678\n",
      "Epoch : 3 Loss: 0.05271359905600548\n",
      "Epoch : 3 Loss: 0.05725209787487984\n",
      "Epoch : 3 Loss: 0.055928658694028854\n",
      "Epoch : 3 Loss: 0.05391169339418411\n",
      "Epoch : 3 Loss: 0.054427675902843475\n",
      "Epoch : 3 Loss: 0.05504319816827774\n",
      "Epoch : 3 Loss: 0.055294785648584366\n",
      "Epoch : 3 Loss: 0.05300673097372055\n",
      "Epoch : 3 Loss: 0.05353294685482979\n",
      "Epoch : 3 Loss: 0.05177263543009758\n",
      "Epoch : 3 Loss: 0.05285647511482239\n",
      "Epoch : 3 Loss: 0.05238711088895798\n",
      "Epoch : 3 Loss: 0.05015663430094719\n",
      "Epoch : 3 Loss: 0.052456632256507874\n",
      "Epoch : 3 Loss: 0.051813315600156784\n",
      "Epoch : 3 Loss: 0.051959432661533356\n",
      "Epoch : 3 Loss: 0.04794527217745781\n",
      "Epoch : 3 Loss: 0.05536545813083649\n",
      "Epoch : 3 Loss: 0.04976758360862732\n",
      "Epoch : 3 Loss: 0.05059851333498955\n",
      "Epoch : 3 Loss: 0.04960208386182785\n",
      "Epoch : 3 Loss: 0.05082748830318451\n",
      "Epoch : 3 Loss: 0.04951823875308037\n",
      "Epoch : 3 Loss: 0.05040697008371353\n",
      "Epoch : 3 Loss: 0.049470383673906326\n",
      "Epoch : 3 Loss: 0.05086960271000862\n",
      "Epoch : 3 Loss: 0.050059493631124496\n",
      "Epoch : 4 Loss: 0.04904651641845703\n",
      "Epoch : 4 Loss: 0.048839278519153595\n",
      "Epoch : 4 Loss: 0.050480954349040985\n",
      "Epoch : 4 Loss: 0.04589422792196274\n",
      "Epoch : 4 Loss: 0.05056201294064522\n",
      "Epoch : 4 Loss: 0.05023776739835739\n",
      "Epoch : 4 Loss: 0.04904697462916374\n",
      "Epoch : 4 Loss: 0.049488697201013565\n",
      "Epoch : 4 Loss: 0.051795702427625656\n",
      "Epoch : 4 Loss: 0.049696795642375946\n",
      "Epoch : 4 Loss: 0.051407814025878906\n",
      "Epoch : 4 Loss: 0.05323483794927597\n",
      "Epoch : 4 Loss: 0.04890245571732521\n",
      "Epoch : 4 Loss: 0.04866422712802887\n",
      "Epoch : 4 Loss: 0.051632240414619446\n",
      "Epoch : 4 Loss: 0.05110224708914757\n",
      "Epoch : 4 Loss: 0.050597164779901505\n",
      "Epoch : 4 Loss: 0.048893366008996964\n",
      "Epoch : 4 Loss: 0.05439144745469093\n",
      "Epoch : 4 Loss: 0.049976177513599396\n",
      "Epoch : 4 Loss: 0.04965471476316452\n",
      "Epoch : 4 Loss: 0.05130061134696007\n",
      "Epoch : 4 Loss: 0.05108513683080673\n",
      "Epoch : 4 Loss: 0.05076516792178154\n",
      "Epoch : 4 Loss: 0.046465203166007996\n",
      "Epoch : 4 Loss: 0.05169309303164482\n",
      "Epoch : 4 Loss: 0.04894491285085678\n",
      "Epoch : 4 Loss: 0.052980076521635056\n",
      "Epoch : 4 Loss: 0.04948757588863373\n",
      "Epoch : 4 Loss: 0.0500156544148922\n",
      "Epoch : 4 Loss: 0.050933610647916794\n",
      "Epoch : 4 Loss: 0.05244756489992142\n",
      "Epoch : 4 Loss: 0.04877397045493126\n",
      "Epoch : 4 Loss: 0.05181663855910301\n",
      "Epoch : 4 Loss: 0.048963118344545364\n",
      "Epoch : 4 Loss: 0.048949386924505234\n",
      "Epoch : 4 Loss: 0.04779748618602753\n",
      "Epoch : 4 Loss: 0.05008677393198013\n",
      "Epoch : 4 Loss: 0.05148429796099663\n",
      "Epoch : 4 Loss: 0.04830174893140793\n",
      "Epoch : 4 Loss: 0.04728596657514572\n",
      "Epoch : 4 Loss: 0.04925978183746338\n",
      "Epoch : 4 Loss: 0.05007566139101982\n",
      "Epoch : 4 Loss: 0.046666037291288376\n",
      "Epoch : 4 Loss: 0.05076118931174278\n",
      "Epoch : 4 Loss: 0.050531286746263504\n",
      "Epoch : 4 Loss: 0.052275508642196655\n",
      "Epoch : 4 Loss: 0.046515025198459625\n",
      "Epoch : 4 Loss: 0.04637058079242706\n",
      "Epoch : 4 Loss: 0.05036776140332222\n",
      "Epoch : 4 Loss: 0.048086728900671005\n",
      "Epoch : 4 Loss: 0.04946890100836754\n",
      "Epoch : 4 Loss: 0.04866340011358261\n",
      "Epoch : 4 Loss: 0.04732026532292366\n",
      "Epoch : 4 Loss: 0.05025477707386017\n",
      "Epoch : 4 Loss: 0.04963632673025131\n",
      "Epoch : 4 Loss: 0.049838218837976456\n",
      "Epoch : 4 Loss: 0.048115696758031845\n",
      "Epoch : 4 Loss: 0.04892463609576225\n",
      "Epoch : 4 Loss: 0.04764208197593689\n",
      "Epoch : 4 Loss: 0.04836985841393471\n",
      "Epoch : 4 Loss: 0.05615830048918724\n",
      "Epoch : 4 Loss: 0.053281717002391815\n",
      "Epoch : 4 Loss: 0.0524551123380661\n",
      "Epoch : 4 Loss: 0.04661046341061592\n",
      "Epoch : 4 Loss: 0.047236427664756775\n",
      "Epoch : 4 Loss: 0.045508548617362976\n",
      "Epoch : 4 Loss: 0.05142253637313843\n",
      "Epoch : 4 Loss: 0.04672430455684662\n",
      "Epoch : 4 Loss: 0.0480838418006897\n",
      "Epoch : 4 Loss: 0.046605437994003296\n",
      "Epoch : 4 Loss: 0.04644592106342316\n",
      "Epoch : 4 Loss: 0.04823204502463341\n",
      "Epoch : 4 Loss: 0.050208672881126404\n",
      "Epoch : 4 Loss: 0.052053436636924744\n",
      "Epoch : 4 Loss: 0.04592594504356384\n",
      "Epoch : 4 Loss: 0.04890154302120209\n",
      "Epoch : 4 Loss: 0.04926670342683792\n",
      "Epoch : 4 Loss: 0.047476980835199356\n",
      "Epoch : 4 Loss: 0.0522422194480896\n",
      "Epoch : 4 Loss: 0.04748358950018883\n",
      "Epoch : 4 Loss: 0.048921551555395126\n",
      "Epoch : 4 Loss: 0.04961675405502319\n",
      "Epoch : 4 Loss: 0.04573243856430054\n",
      "Epoch : 4 Loss: 0.04745912179350853\n",
      "Epoch : 4 Loss: 0.04705190286040306\n",
      "Epoch : 4 Loss: 0.046461641788482666\n",
      "Epoch : 4 Loss: 0.047828055918216705\n",
      "Epoch : 4 Loss: 0.045261889696121216\n",
      "Epoch : 4 Loss: 0.04800604656338692\n",
      "Epoch : 4 Loss: 0.044659942388534546\n",
      "Epoch : 4 Loss: 0.04493042454123497\n",
      "Epoch : 4 Loss: 0.04508809745311737\n",
      "Epoch : 4 Loss: 0.04557422921061516\n",
      "Epoch : 4 Loss: 0.04507813602685928\n",
      "Epoch : 4 Loss: 0.04727039486169815\n",
      "Epoch : 4 Loss: 0.04398188367486\n",
      "Epoch : 4 Loss: 0.04344502091407776\n",
      "Epoch : 4 Loss: 0.045698847621679306\n",
      "Epoch : 4 Loss: 0.04879835993051529\n",
      "Epoch : 4 Loss: 0.046769239008426666\n",
      "Epoch : 4 Loss: 0.04767943173646927\n",
      "Epoch : 4 Loss: 0.04825490713119507\n",
      "Epoch : 4 Loss: 0.046511586755514145\n",
      "Epoch : 4 Loss: 0.047911129891872406\n",
      "Epoch : 4 Loss: 0.04599151760339737\n",
      "Epoch : 4 Loss: 0.048024456948041916\n",
      "Epoch : 4 Loss: 0.048308562487363815\n",
      "Epoch : 4 Loss: 0.045603904873132706\n",
      "Epoch : 4 Loss: 0.04714271053671837\n",
      "Epoch : 4 Loss: 0.04864458367228508\n",
      "Epoch : 4 Loss: 0.04321393743157387\n",
      "Epoch : 4 Loss: 0.045223213732242584\n",
      "Epoch : 4 Loss: 0.04717407003045082\n",
      "Epoch : 4 Loss: 0.054297905415296555\n",
      "Epoch : 4 Loss: 0.044940460473299026\n",
      "Epoch : 4 Loss: 0.04862493649125099\n",
      "Epoch : 4 Loss: 0.04591641575098038\n",
      "Epoch : 4 Loss: 0.044314801692962646\n",
      "Epoch : 4 Loss: 0.0451931357383728\n",
      "Epoch : 4 Loss: 0.047371357679367065\n",
      "Epoch : 4 Loss: 0.045938897877931595\n",
      "Epoch : 4 Loss: 0.0455164797604084\n",
      "Epoch : 4 Loss: 0.048279885202646255\n",
      "Epoch : 4 Loss: 0.044426873326301575\n",
      "Epoch : 4 Loss: 0.04714547097682953\n",
      "Epoch : 4 Loss: 0.05308171734213829\n",
      "Epoch : 4 Loss: 0.04650704190135002\n",
      "Epoch : 4 Loss: 0.045944977551698685\n",
      "Epoch : 4 Loss: 0.04499910771846771\n",
      "Epoch : 4 Loss: 0.04419481381773949\n",
      "Epoch : 4 Loss: 0.04402439296245575\n",
      "Epoch : 4 Loss: 0.045388784259557724\n",
      "Epoch : 4 Loss: 0.04560864716768265\n",
      "Epoch : 4 Loss: 0.04862378165125847\n",
      "Epoch : 4 Loss: 0.0425063893198967\n",
      "Epoch : 4 Loss: 0.04630924388766289\n",
      "Epoch : 4 Loss: 0.04563476890325546\n",
      "Epoch : 4 Loss: 0.044868241995573044\n",
      "Epoch : 4 Loss: 0.04483684152364731\n",
      "Epoch : 4 Loss: 0.044428955763578415\n",
      "Epoch : 4 Loss: 0.05033602565526962\n",
      "Epoch : 4 Loss: 0.04620892181992531\n",
      "Epoch : 4 Loss: 0.0440453439950943\n",
      "Epoch : 4 Loss: 0.0456671267747879\n",
      "Epoch : 4 Loss: 0.05071817338466644\n",
      "Epoch : 4 Loss: 0.0464000478386879\n",
      "Epoch : 4 Loss: 0.051304593682289124\n",
      "Epoch : 4 Loss: 0.04726206883788109\n",
      "Epoch : 4 Loss: 0.04467491805553436\n",
      "Epoch : 4 Loss: 0.04723139479756355\n",
      "Epoch : 4 Loss: 0.04528338089585304\n",
      "Epoch : 4 Loss: 0.048596955835819244\n",
      "Epoch : 4 Loss: 0.04760035127401352\n",
      "Epoch : 4 Loss: 0.0481073372066021\n",
      "Epoch : 4 Loss: 0.045373573899269104\n",
      "Epoch : 4 Loss: 0.044163886457681656\n",
      "Epoch : 4 Loss: 0.046845514327287674\n",
      "Epoch : 4 Loss: 0.04612146317958832\n",
      "Epoch : 4 Loss: 0.0459931418299675\n",
      "Epoch : 4 Loss: 0.04850813001394272\n",
      "Epoch : 4 Loss: 0.0455334447324276\n",
      "Epoch : 4 Loss: 0.04675602167844772\n",
      "Epoch : 4 Loss: 0.04407747834920883\n",
      "Epoch : 4 Loss: 0.04672437533736229\n",
      "Epoch : 4 Loss: 0.04451000690460205\n",
      "Epoch : 4 Loss: 0.04678991064429283\n",
      "Epoch : 4 Loss: 0.0451073981821537\n",
      "Epoch : 4 Loss: 0.04591625556349754\n",
      "Epoch : 4 Loss: 0.046269163489341736\n",
      "Epoch : 4 Loss: 0.048911452293395996\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += loss.item()\n",
    "        print(f'Epoch : {epoch} Loss: {loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pokemodel.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet101()\n",
    "model.fc = nn.Linear(model.fc.in_features, 150)\n",
    "model.load_state_dict(torch.load('pokemodel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "model.eval()\n",
    "\n",
    "img_path = 'test/charmander.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert BGR image to RGB\n",
    "rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Convert the NumPy array image to a PIL Image\n",
    "cv_img = Image.fromarray(rgb_img)\n",
    "\n",
    "# Define the same transformations used during training\n",
    "data_trans = transforms.Compose([\n",
    "                                transforms.Resize((224,224)),\n",
    "                                  transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean = [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = data_trans(cv_img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Get the predicted class (you need to map class indices to Pokemon names)\n",
    "predicted_class = output.argmax().item()\n",
    "# Assuming 'output' is your model's output tensor\n",
    "class_probabilities = torch.softmax(output, dim=1)\n",
    "predicted_class = torch.argmax(class_probabilities, dim=1).item()\n",
    "\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "dataset_dir = 'PokemonData'  # Replace with your dataset path\n",
    "\n",
    "# Get a list of class names from the subfolder names\n",
    "class_names = sorted(os.listdir(dataset_dir))\n",
    "\n",
    "# Create a dictionary to map class indices to Pokemon names\n",
    "class_to_name = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Now, when you have a predicted class index (predicted_class), you can get the Pokemon name\n",
    "predicted_pokemon = class_to_name[predicted_class]\n",
    "\n",
    "cv_img = np.array(img)\n",
    "# Display the image with the predicted classification\n",
    "cv2.putText(cv_img, f' {predicted_pokemon}', (60, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Show the image with the classification\n",
    "cv2.imshow('Pokemon Classification', cv_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
